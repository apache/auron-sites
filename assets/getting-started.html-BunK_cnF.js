import{_ as a,c as n,e as s,o as r}from"./app-7Yi8rA2S.js";const l={};function t(i,e){return r(),n("div",null,[...e[0]||(e[0]=[s(`<h1 id="getting-started-with-auron-for-apache-spark" tabindex="-1"><a class="header-anchor" href="#getting-started-with-auron-for-apache-spark"><span>Getting Started with Auron for Apache Spark</span></a></h1><h2 id="build-from-source" tabindex="-1"><a class="header-anchor" href="#build-from-source"><span>Build from source</span></a></h2><p>To build Auron from source, follow the steps below:</p><ol><li>Install Rust</li></ol><p>Auron&#39;s native execution lib is written in Rust. You need to install Rust (nightly) before compiling.</p><p>We recommend using <a href="https://rustup.rs/" target="_blank" rel="noopener noreferrer">rustup</a> for installation.</p><ol start="2"><li>Install JDK</li></ol><p>Auron has been well tested with JDK 8, 11, and 17.</p><p>Make sure <code>JAVA_HOME</code> is properly set and points to your desired version.</p><ol start="3"><li><p>Check out the source code.</p></li><li><p>Build the project.</p></li></ol><p>You can build Auron either <em>locally</em> or <em>inside Docker with CentOS7</em> using a unified script: <code>auron-build.sh</code>.</p><p>Run <code>./auron-build.sh --help</code> to see all available options.</p><p>After the build completes, a fat JAR with all dependencies will be generated in either the <code>target/</code> directory (for local builds) or <code>target-docker/</code> directory (for Docker builds), depending on the selected build mode.</p><h2 id="run-spark-job-with-auron-accelerator" tabindex="-1"><a class="header-anchor" href="#run-spark-job-with-auron-accelerator"><span>Run Spark Job with Auron Accelerator</span></a></h2><p>This section describes how to submit and configure a Spark Job with Auron support.</p><ol><li><p>Move the Auron JAR to the Spark client classpath (normally spark-xx.xx.xx/jars/).</p></li><li><p>Add the following configs to spark configuration in <code>spark-xx.xx.xx/conf/spark-default.conf</code>:</p></li></ol><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre><code><span class="line"><span class="token key attr-name">spark.auron.enable</span> <span class="token value attr-value">true</span></span>
<span class="line"><span class="token key attr-name">spark.sql.extensions</span> <span class="token value attr-value">org.apache.spark.sql.auron.AuronSparkSessionExtension</span></span>
<span class="line"><span class="token key attr-name">spark.shuffle.manager</span> <span class="token value attr-value">org.apache.spark.sql.execution.auron.shuffle.AuronShuffleManager</span></span>
<span class="line"><span class="token key attr-name">spark.memory.offHeap.enabled</span> <span class="token value attr-value">false</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># suggested executor memory configuration</span></span>
<span class="line"><span class="token key attr-name">spark.executor.memory</span> <span class="token value attr-value">4g</span></span>
<span class="line"><span class="token key attr-name">spark.executor.memoryOverhead</span> <span class="token value attr-value">4096</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>submit a query with spark-sql, or other tools like spark-thriftserver:</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">spark-sql <span class="token parameter variable">-f</span> tpcds/q01.sql</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="integrating-auron-with-remote-shuffle-services-rss" tabindex="-1"><a class="header-anchor" href="#integrating-auron-with-remote-shuffle-services-rss"><span>Integrating Auron with Remote Shuffle Services (RSS)</span></a></h2><p>Auron can be integrated with external Remote Shuffle Services to enhance shuffle performance and improve scalability.</p><p>Currently, the following versions are supported: <code>Apache Celeborn</code> ( <em>0.5.4</em> and <em>0.6</em> ), and <code>Apache Uniffle</code> ( <em>0.9.2</em> ).</p><h3 id="apache-celeborn" tabindex="-1"><a class="header-anchor" href="#apache-celeborn"><span>Apache Celeborn</span></a></h3><p>Auron can work with Celeborn as a shuffle manager. Integration involves configuring Auron/Spark to use the AuronCelebornShuffleManager and pointing it to the appropriate Celeborn master endpoints and storage locations. This allows Spark jobs running on Auron to leverage Celeborn for distributed shuffling.</p><p>You can integrate using the following example configuration:</p><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre><code><span class="line"><span class="token key attr-name">spark.shuffle.manager</span> <span class="token value attr-value">org.apache.spark.sql.execution.auron.shuffle.celeborn.AuronCelebornShuffleManager</span></span>
<span class="line"><span class="token key attr-name">spark.serializer</span> <span class="token value attr-value">org.apache.spark.serializer.KryoSerializer</span></span>
<span class="line"><span class="token key attr-name">spark.celeborn.master.endpoints</span> <span class="token value attr-value">localhost:9097</span></span>
<span class="line"><span class="token key attr-name">spark.celeborn.client.spark.shuffle.writer</span> <span class="token value attr-value">hash</span></span>
<span class="line"><span class="token key attr-name">spark.sql.adaptive.localShuffleReader.enabled</span> <span class="token value attr-value">false</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="apache-uniffle" tabindex="-1"><a class="header-anchor" href="#apache-uniffle"><span>Apache Uniffle</span></a></h3><p>Similarly, Auron also supports Uniffle, you need to configure Auron/Spark to use the AuronUniffleShuffleManager and specify the Uniffle coordinator endpoints.</p><p>You can integrate using the following example configuration:</p><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre><code><span class="line"><span class="token key attr-name">spark.shuffle.manager</span> <span class="token value attr-value">org.apache.spark.sql.execution.auron.shuffle.uniffle.AuronUniffleShuffleManager</span></span>
<span class="line"><span class="token key attr-name">spark.serializer</span> <span class="token value attr-value">org.apache.spark.serializer.KryoSerializer</span></span>
<span class="line"><span class="token key attr-name">spark.rss.coordinator.quorum</span> <span class="token value attr-value">&lt;coordinatorIp1&gt;:19999,&lt;coordinatorIp2&gt;:19999</span></span>
<span class="line"><span class="token key attr-name">spark.rss.enabled</span> <span class="token value attr-value">true</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="notes" tabindex="-1"><a class="header-anchor" href="#notes"><span>Notes</span></a></h3><ol><li><p>Ensure the relevant RSS client JARs are included in your Spark application&#39;s classpath.</p></li><li><p>Replace endpoints and directories with the actual addresses in your cluster.</p></li><li><p>For detailed setup and advanced configuration, refer to the official documentation for the respective:</p><ul><li><a href="https://celeborn.apache.org/docs/latest/" target="_blank" rel="noopener noreferrer">Celeborn</a></li><li><a href="https://uniffle.apache.org/docs/client-guide" target="_blank" rel="noopener noreferrer">Uniffle</a></li></ul></li></ol>`,32)])])}const p=a(l,[["render",t]]),c=JSON.parse('{"path":"/documents/getting-started.html","title":"Getting-Started","lang":"en-US","frontmatter":{"title":"Getting-Started"},"headers":[{"level":2,"title":"Build from source","slug":"build-from-source","link":"#build-from-source","children":[]},{"level":2,"title":"Run Spark Job with Auron Accelerator","slug":"run-spark-job-with-auron-accelerator","link":"#run-spark-job-with-auron-accelerator","children":[]},{"level":2,"title":"Integrating Auron with Remote Shuffle Services (RSS)","slug":"integrating-auron-with-remote-shuffle-services-rss","link":"#integrating-auron-with-remote-shuffle-services-rss","children":[{"level":3,"title":"Apache Celeborn","slug":"apache-celeborn","link":"#apache-celeborn","children":[]},{"level":3,"title":"Apache Uniffle","slug":"apache-uniffle","link":"#apache-uniffle","children":[]},{"level":3,"title":"Notes","slug":"notes","link":"#notes","children":[]}]}],"git":{},"filePathRelative":"documents/getting-started.md"}');export{p as comp,c as data};
